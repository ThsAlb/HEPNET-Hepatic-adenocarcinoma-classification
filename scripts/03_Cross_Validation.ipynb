{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Purpose:\n",
    "To perform stratified K-Fold-Cross-Validation\n",
    "\n",
    "Prerequisite:\n",
    "Download most current weights of imagenet database for transfer learning\n",
    "!wget https://storage.googleapis.com/cloud-tpu-checkpoints/efficientnet/noisystudent/noisy_student_efficientnet-b3.tar.gz -P /home/thomas/Projects/ICCAvsMETS/weights\n",
    "!tar -xf /home/thomas/Projects/ICCAvsMETS/weights/noisy_student_efficientnet-b3.tar.gz -C /home/thomas/Projects/ICCAvsMETS/weights\n",
    "!python /home/thomas/Projects/VENV/efficientnet_weight_update_util.py --model b3 --notop --ckpt /home/thomas/Projects/ICCAvsMETS/weights/noisy-student-efficientnet-b3/model.ckpt --o /home/thomas/Projects/ICCAvsMETS/weights/noisy-student-efficientnet-b3/efficientnetb3_notop.h5\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all required libraries\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.stats as st\n",
    "import scikitplot as skplt\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from numpy import asarray\n",
    "from numpy import savetxt, loadtxt\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set current working directory (source for image tiles)\n",
    "os.chdir(\"/media/data/Projects/ICCAVSMETS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set project directory (model-relevant and processed data)\n",
    "SSDDir = '/home/thomas/Projects/ICCAvsMETS'\n",
    "FiguresDir = SSDDir+'/Figures/CrossValidation/'\n",
    "model_dir = SSDDir+'/saved_models/CrossValidation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define folder of source image tiles: folders should have the following hierachy: */Category/Material/**.jpg\n",
    "NormalizedTiles = 'Tiles/Normalized'\n",
    "Sets = 'Tiles/Sets'\n",
    "TrainingSetDir = 'Tiles/Sets/Train'\n",
    "TestSetDir = 'Tiles/Sets/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define lists\n",
    "PatientNo = []\n",
    "Category = []\n",
    "Tilename = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get FrozenModel name for each of the k iterations\n",
    "def get_frozen_model_name(k):\n",
    "    return 'frozen_model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-daniel",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get tuned Model name for each of the k iterations\n",
    "def get_tuned_model_name(k):\n",
    "    return 'tuned_model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-alexander",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ungroup the tables for each fold\n",
    "def ungroup_data_table(DataTable):\n",
    "\n",
    "    Tilenames_new = []\n",
    "    Tilenames_flatten = []\n",
    "    Category_new = []\n",
    "    PatientNo_new = []\n",
    "    n = 0\n",
    "\n",
    "    for i in DataTable['Tilenames']:\n",
    "        Tilenames_new.append(i)\n",
    "        for a in range(i.count(', ')+1):\n",
    "            PatientNo_new.append(DataTable.loc[n, 'PatientNo'])\n",
    "            Category_new.append(DataTable.loc[n, 'Category'])\n",
    "        n = n + 1\n",
    "\n",
    "    Tilenames_flatten = [inner for item in Tilenames_new for inner in ast.literal_eval(item)] \n",
    "    Ungrouped_DataTable = pd.DataFrame({'PatientNo': PatientNo_new, 'Category': Category_new, 'Tilenames': Tilenames_flatten})\n",
    "    return Ungrouped_DataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read TrainingSet Table\n",
    "TrainTable = pd.read_csv(SSDDir+'/Tables/TrainTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fixed Parameters\n",
    "num_classes = TrainTable['Category'].nunique()\n",
    "if num_classes == 2:\n",
    "    num_classes = num_classes-1\n",
    "num_patients = len(TrainTable.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Variable Parameters\n",
    "num_epochs = 100\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "IMAGE_SIZE = [img_height, img_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demographic-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Target Variable and create instance of stratifiedkfold\n",
    "y = TrainTable['Category']\n",
    "skf = StratifiedKFold(n_splits = 4, random_state = 7, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create instances of ImageDataGenerators for train and validation set\n",
    "idg_train = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   vertical_flip=True,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "idg_valid = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Destination of precalibrated weights\n",
    "weights_B3 = '/home/thomas/Projects/ICCAvsMETS/weights/noisy-student-efficientnet-b3/efficientnetb3_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performing cross-validation via K-Fold-Splitting, Transfer learning and Fine Tuning\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "best_epochs_transfer = []\n",
    "best_epochs_tuning = []\n",
    "top_dropout_rate = 0.2\n",
    "fold_var = 1\n",
    "\n",
    "probabilities_tiles = []\n",
    "probabilities_patient = []\n",
    "\n",
    "## Loop over each fold of K-Fold-Splitting\n",
    "for train_index, val_index in skf.split(np.zeros(num_patients),y):\n",
    "        training_data_grouped = TrainTable.iloc[train_index].reset_index(drop=True)\n",
    "        validation_data_grouped = TrainTable.iloc[val_index].reset_index(drop=True)\n",
    "        \n",
    "        training_data = ungroup_data_table(training_data_grouped)\n",
    "        validation_data = ungroup_data_table(validation_data_grouped)\n",
    "        \n",
    "        train_data_generator = idg_train.flow_from_dataframe(training_data, directory = TrainingSetDir,\n",
    "                                                       x_col = \"Tilenames\", y_col = \"Category\", \n",
    "                                                       batch_size = 32,\n",
    "                                                       target_size = (img_height, img_width),\n",
    "                                                       class_mode = \"binary\", shuffle = True)\n",
    "        valid_data_generator  = idg_valid.flow_from_dataframe(validation_data, directory = TrainingSetDir,\n",
    "                                                        x_col = \"Tilenames\", y_col = \"Category\",\n",
    "                                                        target_size = (img_height, img_width),\n",
    "                                                        class_mode = \"binary\", shuffle = False)\n",
    "        \n",
    "        # CREATE NEW MODEL\n",
    "        inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "        base = EfficientNetB3 (include_top=False, weights=weights_B3, input_tensor=inputs, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "        # Freeze the pretrained weights\n",
    "        base.trainable = False\n",
    "\n",
    "        # Rebuild top (IMPORTANT: run in inference mode by setting training=false for finetuning)\n",
    "        top_activation_layer = base.get_layer('top_activation')\n",
    "        x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(top_activation_layer.output)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "        x = layers.Dense(num_classes, activation=\"sigmoid\", name=\"pred\")(x)\n",
    "        \n",
    "        MyModel = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "        # COMPILE NEW MODEL\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "        MyModel.compile(loss='binary_crossentropy',\n",
    "                        optimizer=opt,\n",
    "                        metrics=['accuracy'])\n",
    "     \n",
    "        # CREATE CALLBACKS\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(model_dir+get_frozen_model_name(fold_var), \n",
    "                                                        monitor='val_loss', verbose=1, \n",
    "                                                        save_best_only=True, mode='min')\n",
    "        callbacks_list = [es, checkpoint]\n",
    "                \n",
    "        # Set step size\n",
    "        STEP_SIZE_TRAIN=train_data_generator.n//train_data_generator.batch_size\n",
    "        STEP_SIZE_VALID=valid_data_generator.n//valid_data_generator.batch_size\n",
    "        \n",
    "        # FIT THE MODEL\n",
    "        history = MyModel.fit(train_data_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              epochs=num_epochs,\n",
    "                              validation_data=valid_data_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callbacks_list)\n",
    "        hist = MyModel.history.history['val_loss']\n",
    "        n_epochs_best = np.argmin(hist) + 1\n",
    "        best_epochs_transfer.append(n_epochs_best)\n",
    "                                    \n",
    "        ## LOAD BEST MODEL WEIGHTS FOR FINETUNING\n",
    "        MyModel.load_weights(model_dir+get_frozen_model_name(fold_var))\n",
    "        \n",
    "        # Unfreeze the base model\n",
    "        base.trainable = True\n",
    "        for layer in MyModel.layers:\n",
    "            if isinstance(layer, layers.BatchNormalization):\n",
    "                layer.trainable = False\n",
    "        \n",
    "        # Recompile\n",
    "        opt2 = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "        MyModel.compile(loss='binary_crossentropy',\n",
    "                        optimizer=opt2,\n",
    "                        metrics=['accuracy'])\n",
    "        \n",
    "        # CREATE NEW CALLBACKS\n",
    "        es2 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "        checkpoint2 = tf.keras.callbacks.ModelCheckpoint(model_dir+get_tuned_model_name(fold_var), \n",
    "                                                         monitor='val_loss', verbose=1, \n",
    "                                                         save_best_only=True, mode='min')\n",
    "        callbacks_list2 = [es2, checkpoint2]\n",
    "        \n",
    "        # Fine tuning\n",
    "        history = MyModel.fit(train_data_generator,\n",
    "                              steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              epochs=num_epochs,\n",
    "                              validation_data=valid_data_generator,\n",
    "                              validation_steps=STEP_SIZE_VALID,\n",
    "                              callbacks=callbacks_list2)\n",
    "        hist = MyModel.history.history['val_loss']\n",
    "        n_epochs_best = np.argmin(hist) + 1\n",
    "        best_epochs_tuning.append(n_epochs_best)\n",
    "        \n",
    "        # LOAD BEST MODEL TO EVALUATE FINAL PERFORMANCE\n",
    "        MyModel.load_weights(model_dir+get_tuned_model_name(fold_var))\n",
    "        \n",
    "        results = MyModel.evaluate(valid_data_generator)\n",
    "        results = dict(zip(MyModel.metrics_names,results))\n",
    "        \n",
    "        VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "        VALIDATION_LOSS.append(results['loss'])\n",
    "        \n",
    "        ## Save Dataframe for Tile Prediction\n",
    "        predictions = MyModel.predict(valid_data_generator)\n",
    "        PredTableTileLevel = validation_data.copy()\n",
    "        PredTableTileLevel['Predictions'] = predictions    \n",
    "        probabilities_tiles.append(PredTableTileLevel)\n",
    "        PredTableTileLevel.to_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTableTileLevel_cv_'+str(fold_var)+'.csv', index=False)\n",
    "        \n",
    "        ## Save Dataframe for Patient Prediction\n",
    "        PredTablePatientLevel = PredTableTileLevel.groupby(['PatientNo', 'Category'])['Predictions'].agg(list).reset_index()\n",
    "        PredTablePatientLevel['Predictions_mean'] = PredTablePatientLevel['Predictions'].apply(np.mean)\n",
    "        probabilities_patient.append(PredTablePatientLevel)\n",
    "        PredTablePatientLevel.to_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTablePatientLevel_cv_'+str(fold_var)+'.csv', index=False)\n",
    "       \n",
    "        PredTablePatientLevel = []\n",
    "        PredTableTileLevel = []\n",
    "    \n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "        fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all dataframes\n",
    "probabilities_tiles = []\n",
    "probabilities_patient = []\n",
    "\n",
    "PredTablePatientLevel1 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTablePatientLevel_cv_1.csv')\n",
    "PredTablePatientLevel2 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTablePatientLevel_cv_2.csv')\n",
    "PredTablePatientLevel3 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTablePatientLevel_cv_3.csv')\n",
    "PredTablePatientLevel4 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTablePatientLevel_cv_4.csv')\n",
    "probabilities_patient.append(PredTablePatientLevel1)\n",
    "probabilities_patient.append(PredTablePatientLevel2)\n",
    "probabilities_patient.append(PredTablePatientLevel3)\n",
    "probabilities_patient.append(PredTablePatientLevel4)\n",
    "\n",
    "PredTableTileLevel1 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTableTileLevel_cv_1.csv')\n",
    "PredTableTileLevel2 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTableTileLevel_cv_2.csv')\n",
    "PredTableTileLevel3 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTableTileLevel_cv_3.csv')\n",
    "PredTableTileLevel4 = pd.read_csv('/home/thomas/Projects/ICCAvsMETS/Tables/PredTableTileLevel_cv_4.csv')\n",
    "probabilities_tiles.append(PredTableTileLevel1)\n",
    "probabilities_tiles.append(PredTableTileLevel2)\n",
    "probabilities_tiles.append(PredTableTileLevel3)\n",
    "probabilities_tiles.append(PredTableTileLevel4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ROC-Curves Tiles Level (Validation-Set)\n",
    "tprs = []\n",
    "aucs = []\n",
    "i = 1\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "colors = ['red', 'green', 'yellow', 'purple']\n",
    "\n",
    "for dataframe in probabilities_tiles:\n",
    "    fpr, tpr, thresholds = roc_curve(dataframe['Category'], dataframe['Predictions'], pos_label='KolonMet')\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1.0, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc), color = colors[i-1], zorder=3)\n",
    "    i = i + 1\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.3f)' % (mean_auc),\n",
    "        lw=1, zorder=2)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "alpha = 0.95\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(aucs, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(aucs, p))\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='moccasin',\n",
    "                 label='$\\pm$ 1 std. dev.', zorder=1)\n",
    "plt.plot([0,1],[0,1],'k--',linewidth = 1.0, color = 'black')\n",
    "plt.xlabel('False positive rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True positive rate', fontsize=12, fontweight='bold')\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "leg = plt.legend(loc='lower right', fontsize=8)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "plt.gca().spines['left'].set_zorder(2)\n",
    "plt.gca().spines['top'].set_zorder(2)\n",
    "plt.savefig(FiguresDir+'ROC_CV_TileLV.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine optimal threshold via Youden statistics\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold_TileLevel = thresholds[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot ROC-Curves Patient Level\n",
    "tprs = []\n",
    "aucs = []\n",
    "i = 1\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "colors = ['red', 'green', 'yellow', 'purple']\n",
    "\n",
    "for dataframe in probabilities_patient:\n",
    "    fpr, tpr, thresholds = roc_curve(dataframe['Category'], dataframe['Predictions_mean'], pos_label='KolonMet')\n",
    "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    tprs.append(interp_tpr)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc), color = colors[i-1], zorder=3)\n",
    "    i = i + 1\n",
    "\n",
    "plt.plot([0,1],[0,1],linestyle = '--',lw = 1,color = 'black')\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "        label=r'Mean ROC (AUC = %0.3f)' % (mean_auc),\n",
    "        lw=1, zorder=2)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "alpha = 0.95\n",
    "p = ((1.0-alpha)/2.0) * 100\n",
    "lower = max(0.0, np.percentile(aucs, p))\n",
    "p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "upper = min(1.0, np.percentile(aucs, p))\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='moccasin',\n",
    "                 label='$\\pm$ 1 std. dev.', zorder=1)\n",
    "\n",
    "plt.xlabel('False positive rate', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True positive rate', fontsize=12, fontweight='bold')\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=10)\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "leg = plt.legend(loc='lower right', fontsize=8)\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "plt.gca().spines['left'].set_zorder(2)\n",
    "plt.gca().spines['top'].set_zorder(2)\n",
    "plt.savefig(FiguresDir+'ROC_CV_PatientLV.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine optimal threshold on patient level\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold_PatientLevel = thresholds[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Thresholds\n",
    "Thresholds_CV = np.asarray([optimal_threshold_TileLevel, optimal_threshold_PatientLevel])\n",
    "savetxt('/home/thomas/Projects/ICCAvsMETS/Tables/Thresholds_CV.csv', Thresholds_CV, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define positive and negative category\n",
    "PosCategory = 'KolonMet'\n",
    "NegCategory = 'ICCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find predicted class and append in list on tile level\n",
    "predicted_class = []\n",
    "for dataframe in probabilities_tiles:\n",
    "    for i in dataframe['Predictions']:\n",
    "        if i > 0.5:\n",
    "            predicted_class.append(PosCategory)\n",
    "        else:\n",
    "            predicted_class.append(NegCategory)\n",
    "    dataframe['PredictedClass'] = predicted_class\n",
    "    predicted_class = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find predicted class and append in list on patient level\n",
    "predicted_class = []\n",
    "for dataframe in probabilities_patient:\n",
    "    for i in dataframe['Predictions_mean']:\n",
    "        if i > 0.5:\n",
    "            predicted_class.append(PosCategory)\n",
    "        else:\n",
    "            predicted_class.append(NegCategory)\n",
    "    dataframe['PredictedClass'] = predicted_class\n",
    "    predicted_class = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix on patient level (absolute), using best run\n",
    "skplt.metrics.plot_confusion_matrix(PredTablePatientLevel4['Category'], PredTablePatientLevel4['PredictedClass'], title = ' ', figsize = (4,3),normalize=False)\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.ylabel('Ground Truth', fontweight='bold')\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(locs,['iCCA', 'CRM'])\n",
    "locs, labels = plt.yticks() \n",
    "plt.yticks(locs,['iCCA', 'CRM'])\n",
    "plt.savefig(FiguresDir+'CoMa_Test_CV_PatientLV_abs.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix on patient level (relative), using best run\n",
    "skplt.metrics.plot_confusion_matrix(PredTablePatientLevel4['Category'], PredTablePatientLevel4['PredictedClass'], title = ' ', figsize = (4,3),normalize=True)\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.ylabel('Ground Truth', fontweight='bold')\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(locs,['iCCA', 'CRM'])\n",
    "locs, labels = plt.yticks() \n",
    "plt.yticks(locs,['iCCA', 'CRM'])\n",
    "plt.savefig(FiguresDir+'CoMa_Test_CV_PatientLV_rel.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix on tile level (absolute), using best run\n",
    "skplt.metrics.plot_confusion_matrix(PredTableTileLevel4['Category'], PredTableTileLevel4['PredictedClass'], title = ' ', figsize = (4,3), normalize=False)\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.ylabel('Ground Truth', fontweight='bold')\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(locs,['iCCA', 'CRM'])\n",
    "locs, labels = plt.yticks() \n",
    "plt.yticks(locs,['iCCA', 'CRM'])\n",
    "plt.savefig(FiguresDir+'CoMa_Test_CV_TileLV_abs.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix on tile level (relative), best run\n",
    "skplt.metrics.plot_confusion_matrix(PredTableTileLevel4['Category'], PredTableTileLevel4['PredictedClass'], title = ' ', figsize = (4,3), normalize=True)\n",
    "plt.xlabel('Predicted', fontweight='bold')\n",
    "plt.ylabel('Ground Truth', fontweight='bold')\n",
    "locs, labels = plt.xticks() \n",
    "plt.xticks(locs,['iCCA', 'CRM'])\n",
    "locs, labels = plt.yticks() \n",
    "plt.yticks(locs,['iCCA', 'CRM'])\n",
    "plt.savefig(FiguresDir+'CoMa_Test_CV_TileLV_rel.png', dpi=1200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compute metrics on tile level. Arbritarly, colorectal metastasis is defined as disease.  \n",
    "Metrics_TileLevel_CV = pd.DataFrame(columns=['Name', 'Accuracy','Sensitivity','Specificity','PPV','NPV'])\n",
    "names = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Mean', 'SD']\n",
    "Metrics_TileLevel_CV['Name'] = names\n",
    "accuracy_list = []\n",
    "accuracy_list_stats = []\n",
    "sensitivity_list = []\n",
    "sensitivity_list_stats = []\n",
    "specificity_list = []\n",
    "specificity_list_stats = []\n",
    "ppv_list = []\n",
    "ppv_list_stats = []\n",
    "npv_list = []\n",
    "npv_list_stats = []\n",
    "\n",
    "for dataframe in probabilities_tiles:\n",
    "    KolonMet_TileNo = dataframe.loc[dataframe['Category'] == 'KolonMet'].shape[0]\n",
    "    KolonMet_correct = dataframe.loc[(dataframe['Category'] == 'KolonMet') & (dataframe['PredictedClass'] == 'KolonMet')].shape[0]\n",
    "    KolonMet_allPositive = dataframe.loc[dataframe['PredictedClass'] == 'KolonMet'].shape[0]\n",
    "    KolonMet_allNegative = dataframe.loc[dataframe['PredictedClass'] == 'ICCA'].shape[0]\n",
    "    KolonMet_correctneg = dataframe.loc[(dataframe['Category'] == 'ICCA') & (dataframe['PredictedClass'] == 'ICCA')].shape[0]\n",
    "\n",
    "    ICCA_TileNo = dataframe.loc[dataframe['Category'] == 'ICCA'].shape[0]\n",
    "    ICCA_correct = dataframe.loc[(dataframe['Category'] == 'ICCA') & (dataframe['PredictedClass'] == 'ICCA')].shape[0]\n",
    "\n",
    "    accuracy_list.append(np.round(((KolonMet_correct+ICCA_correct)/(KolonMet_TileNo+ICCA_TileNo))*100,2))\n",
    "    sensitivity_list.append(np.round((KolonMet_correct/KolonMet_TileNo)*100,2))\n",
    "    specificity_list.append(np.round((ICCA_correct/ICCA_TileNo)*100,2))\n",
    "    ppv_list.append(np.round((KolonMet_correct/KolonMet_allPositive)*100,2))\n",
    "    npv_list.append(np.round((KolonMet_correctneg/KolonMet_allNegative)*100,2))\n",
    "\n",
    "accuracy_list_stats.append(np.round((np.mean(accuracy_list)),3))\n",
    "accuracy_list_stats.append(np.round((np.std(accuracy_list)),3))\n",
    "sensitivity_list_stats.append(np.round((np.mean(sensitivity_list)),3))\n",
    "sensitivity_list_stats.append(np.round((np.std(sensitivity_list)),3))\n",
    "specificity_list_stats.append(np.round((np.mean(specificity_list)),3))\n",
    "specificity_list_stats.append(np.round((np.std(specificity_list)),3))\n",
    "ppv_list_stats.append(np.round((np.mean(ppv_list)),3))\n",
    "ppv_list_stats.append(np.round((np.std(ppv_list)),3))\n",
    "npv_list_stats.append(np.round((np.mean(npv_list)),3))\n",
    "npv_list_stats.append(np.round((np.std(npv_list)),3))\n",
    "\n",
    "accuracy_list.extend(accuracy_list_stats)\n",
    "sensitivity_list.extend(sensitivity_list_stats)\n",
    "specificity_list.extend(specificity_list_stats)\n",
    "ppv_list.extend(ppv_list_stats)\n",
    "npv_list.extend(npv_list_stats)\n",
    "                \n",
    "Metrics_TileLevel_CV['Accuracy']=accuracy_list\n",
    "Metrics_TileLevel_CV['Sensitivity']=sensitivity_list\n",
    "Metrics_TileLevel_CV['Specificity']=specificity_list\n",
    "Metrics_TileLevel_CV['PPV']=ppv_list\n",
    "Metrics_TileLevel_CV['NPV']=npv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save tile metrics to csv\n",
    "Metrics_TileLevel_CV.to_csv('/home/thomas/Projects/ICCAvsMETS/Tables/Metrics_TileLevel_CV.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compute metrics on patient level. Arbritarly, colorectal metastasis is defined as disease. \n",
    "Metrics_PatientLevel_CV = pd.DataFrame(columns=['Name', 'Accuracy','Sensitivity','Specificity','PPV','NPV'])\n",
    "names = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Mean', 'SD']\n",
    "Metrics_PatientLevel_CV['Name'] = names\n",
    "accuracy_list = []\n",
    "accuracy_list_stats = []\n",
    "sensitivity_list = []\n",
    "sensitivity_list_stats = []\n",
    "specificity_list = []\n",
    "specificity_list_stats = []\n",
    "ppv_list = []\n",
    "ppv_list_stats = []\n",
    "npv_list = []\n",
    "npv_list_stats = []\n",
    "\n",
    "for dataframe in probabilities_patient:\n",
    "    KolonMet_PatientNo = dataframe.loc[dataframe['Category'] == 'KolonMet'].shape[0]\n",
    "    KolonMet_correct = dataframe.loc[(dataframe['Category'] == 'KolonMet') & (dataframe['PredictedClass'] == 'KolonMet')].shape[0]\n",
    "    KolonMet_allPositive = dataframe.loc[dataframe['PredictedClass'] == 'KolonMet'].shape[0]\n",
    "    KolonMet_allNegative = dataframe.loc[dataframe['PredictedClass'] == 'ICCA'].shape[0]\n",
    "    KolonMet_correctneg = dataframe.loc[(dataframe['Category'] == 'ICCA') & (dataframe['PredictedClass'] == 'ICCA')].shape[0]\n",
    "\n",
    "    ICCA_PatientNo = dataframe.loc[dataframe['Category'] == 'ICCA'].shape[0]\n",
    "    ICCA_correct = dataframe.loc[(dataframe['Category'] == 'ICCA') & (dataframe['PredictedClass'] == 'ICCA')].shape[0]\n",
    "\n",
    "    accuracy_list.append(np.round(((KolonMet_correct+ICCA_correct)/(KolonMet_PatientNo+ICCA_PatientNo))*100,2))\n",
    "    sensitivity_list.append(np.round((KolonMet_correct/KolonMet_PatientNo)*100,2))\n",
    "    specificity_list.append(np.round((ICCA_correct/ICCA_PatientNo)*100,2))\n",
    "    ppv_list.append(np.round((KolonMet_correct/KolonMet_allPositive)*100,2))\n",
    "    npv_list.append(np.round((KolonMet_correctneg/KolonMet_allNegative)*100,2))\n",
    "\n",
    "accuracy_list_stats.append(np.round((np.mean(accuracy_list)),3))\n",
    "accuracy_list_stats.append(np.round((np.std(accuracy_list)),3))\n",
    "sensitivity_list_stats.append(np.round((np.mean(sensitivity_list)),3))\n",
    "sensitivity_list_stats.append(np.round((np.std(sensitivity_list)),3))\n",
    "specificity_list_stats.append(np.round((np.mean(specificity_list)),3))\n",
    "specificity_list_stats.append(np.round((np.std(specificity_list)),3))\n",
    "ppv_list_stats.append(np.round((np.mean(ppv_list)),3))\n",
    "ppv_list_stats.append(np.round((np.std(ppv_list)),3))\n",
    "npv_list_stats.append(np.round((np.mean(npv_list)),3))\n",
    "npv_list_stats.append(np.round((np.std(npv_list)),3))\n",
    "\n",
    "accuracy_list.extend(accuracy_list_stats)\n",
    "sensitivity_list.extend(sensitivity_list_stats)\n",
    "specificity_list.extend(specificity_list_stats)\n",
    "ppv_list.extend(ppv_list_stats)\n",
    "npv_list.extend(npv_list_stats)\n",
    "    \n",
    "Metrics_PatientLevel_CV['Accuracy']=accuracy_list\n",
    "Metrics_PatientLevel_CV['Sensitivity']=sensitivity_list\n",
    "Metrics_PatientLevel_CV['Specificity']=specificity_list\n",
    "Metrics_PatientLevel_CV['PPV']=ppv_list\n",
    "Metrics_PatientLevel_CV['NPV']=npv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save patient level metrics to csv\n",
    "Metrics_PatientLevel_CV.to_csv('/home/thomas/Projects/ICCAvsMETS/Tables/Metrics_PatientLevel_CV.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print validation accuracies and loss for each run\n",
    "AVG_VALIDATION_ACCURACY = np.mean(VALIDATION_ACCURACY)\n",
    "AVG_VALIDATION_LOSS = np.mean(VALIDATION_LOSS)\n",
    "SDV_acc = np.std (VALIDATION_ACCURACY)\n",
    "SDV_loss = np.std (VALIDATION_LOSS)\n",
    "for item in VALIDATION_ACCURACY: print('Validation Accuracy: '+ str(item))\n",
    "for item in VALIDATION_LOSS: print('Validation Loss: '+ str(item))\n",
    "print('Average Validation Accuracy: '+str(AVG_VALIDATION_ACCURACY)+' +/- '+str(SDV_acc))\n",
    "print('Average Validation Loss: '+str(AVG_VALIDATION_LOSS)+' +/- '+str(SDV_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.5",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
